 
---------- Step 0: Installing libraries  --------------
 
Collecting librosa
  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)
Collecting audioread>=2.1.9 (from librosa)
  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)
Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from librosa) (1.26.4)
Requirement already satisfied: scipy>=1.2.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from librosa) (1.13.1)
Collecting scikit-learn>=0.20.0 (from librosa)
  Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Requirement already satisfied: joblib>=0.14 in /scratch/skscla001/.local/lib/python3.9/site-packages (from librosa) (1.4.2)
Requirement already satisfied: decorator>=4.3.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from librosa) (5.2.1)
Collecting numba>=0.51.0 (from librosa)
  Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)
Collecting soundfile>=0.12.1 (from librosa)
  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)
Collecting pooch>=1.1 (from librosa)
  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)
Collecting soxr>=0.3.2 (from librosa)
  Downloading soxr-0.5.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)
Requirement already satisfied: typing-extensions>=4.1.1 in /scratch/skscla001/.local/lib/python3.9/site-packages (from librosa) (4.12.2)
Collecting lazy-loader>=0.1 (from librosa)
  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)
Collecting msgpack>=1.0 (from librosa)
  Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)
Requirement already satisfied: packaging in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from lazy-loader>=0.1->librosa) (24.1)
Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.0->librosa)
  Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)
Requirement already satisfied: platformdirs>=2.5.0 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from pooch>=1.1->librosa) (3.10.0)
Requirement already satisfied: requests>=2.19.0 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.32.3)
Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.20.0->librosa)
  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: cffi>=1.0 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)
Requirement already satisfied: pycparser in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)
Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)
Downloading audioread-3.0.1-py3-none-any.whl (23 kB)
Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)
Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (377 kB)
Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 86.1 MB/s eta 0:00:00
Downloading pooch-1.8.2-py3-none-any.whl (64 kB)
Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 102.4 MB/s eta 0:00:00
Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 48.5 MB/s eta 0:00:00
Downloading soxr-0.5.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253 kB)
Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 105.3 MB/s eta 0:00:00
Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Installing collected packages: threadpoolctl, soxr, msgpack, llvmlite, lazy-loader, audioread, soundfile, scikit-learn, pooch, numba, librosa
Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.43.0 msgpack-1.1.0 numba-0.60.0 pooch-1.8.2 scikit-learn-1.6.1 soundfile-0.13.1 soxr-0.5.0.post1 threadpoolctl-3.5.0
---------- Step 1: Running model ----------------------
/scratch/skscla001/speech/adapter-wavlm/ASR/utils.py:9: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("sox_io")
Some weights of AdaWavLMForCTC were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.layers.0.adapter_layer_attn.layernorm.bias', 'encoder.layers.0.adapter_layer_attn.layernorm.weight', 'encoder.layers.0.adapter_layer_attn.linear_down.bias', 'encoder.layers.0.adapter_layer_attn.linear_down.weight', 'encoder.layers.0.adapter_layer_attn.linear_up.bias', 'encoder.layers.0.adapter_layer_attn.linear_up.weight', 'encoder.layers.0.adapter_layer_ff.layernorm.bias', 'encoder.layers.0.adapter_layer_ff.layernorm.weight', 'encoder.layers.0.adapter_layer_ff.linear_down.bias', 'encoder.layers.0.adapter_layer_ff.linear_down.weight', 'encoder.layers.0.adapter_layer_ff.linear_up.bias', 'encoder.layers.0.adapter_layer_ff.linear_up.weight', 'encoder.layers.1.adapter_layer_attn.layernorm.bias', 'encoder.layers.1.adapter_layer_attn.layernorm.weight', 'encoder.layers.1.adapter_layer_attn.linear_down.bias', 'encoder.layers.1.adapter_layer_attn.linear_down.weight', 'encoder.layers.1.adapter_layer_attn.linear_up.bias', 'encoder.layers.1.adapter_layer_attn.linear_up.weight', 'encoder.layers.1.adapter_layer_ff.layernorm.bias', 'encoder.layers.1.adapter_layer_ff.layernorm.weight', 'encoder.layers.1.adapter_layer_ff.linear_down.bias', 'encoder.layers.1.adapter_layer_ff.linear_down.weight', 'encoder.layers.1.adapter_layer_ff.linear_up.bias', 'encoder.layers.1.adapter_layer_ff.linear_up.weight', 'encoder.layers.10.adapter_layer_attn.layernorm.bias', 'encoder.layers.10.adapter_layer_attn.layernorm.weight', 'encoder.layers.10.adapter_layer_attn.linear_down.bias', 'encoder.layers.10.adapter_layer_attn.linear_down.weight', 'encoder.layers.10.adapter_layer_attn.linear_up.bias', 'encoder.layers.10.adapter_layer_attn.linear_up.weight', 'encoder.layers.10.adapter_layer_ff.layernorm.bias', 'encoder.layers.10.adapter_layer_ff.layernorm.weight', 'encoder.layers.10.adapter_layer_ff.linear_down.bias', 'encoder.layers.10.adapter_layer_ff.linear_down.weight', 'encoder.layers.10.adapter_layer_ff.linear_up.bias', 'encoder.layers.10.adapter_layer_ff.linear_up.weight', 'encoder.layers.11.adapter_layer_attn.layernorm.bias', 'encoder.layers.11.adapter_layer_attn.layernorm.weight', 'encoder.layers.11.adapter_layer_attn.linear_down.bias', 'encoder.layers.11.adapter_layer_attn.linear_down.weight', 'encoder.layers.11.adapter_layer_attn.linear_up.bias', 'encoder.layers.11.adapter_layer_attn.linear_up.weight', 'encoder.layers.11.adapter_layer_ff.layernorm.bias', 'encoder.layers.11.adapter_layer_ff.layernorm.weight', 'encoder.layers.11.adapter_layer_ff.linear_down.bias', 'encoder.layers.11.adapter_layer_ff.linear_down.weight', 'encoder.layers.11.adapter_layer_ff.linear_up.bias', 'encoder.layers.11.adapter_layer_ff.linear_up.weight', 'encoder.layers.2.adapter_layer_attn.layernorm.bias', 'encoder.layers.2.adapter_layer_attn.layernorm.weight', 'encoder.layers.2.adapter_layer_attn.linear_down.bias', 'encoder.layers.2.adapter_layer_attn.linear_down.weight', 'encoder.layers.2.adapter_layer_attn.linear_up.bias', 'encoder.layers.2.adapter_layer_attn.linear_up.weight', 'encoder.layers.2.adapter_layer_ff.layernorm.bias', 'encoder.layers.2.adapter_layer_ff.layernorm.weight', 'encoder.layers.2.adapter_layer_ff.linear_down.bias', 'encoder.layers.2.adapter_layer_ff.linear_down.weight', 'encoder.layers.2.adapter_layer_ff.linear_up.bias', 'encoder.layers.2.adapter_layer_ff.linear_up.weight', 'encoder.layers.3.adapter_layer_attn.layernorm.bias', 'encoder.layers.3.adapter_layer_attn.layernorm.weight', 'encoder.layers.3.adapter_layer_attn.linear_down.bias', 'encoder.layers.3.adapter_layer_attn.linear_down.weight', 'encoder.layers.3.adapter_layer_attn.linear_up.bias', 'encoder.layers.3.adapter_layer_attn.linear_up.weight', 'encoder.layers.3.adapter_layer_ff.layernorm.bias', 'encoder.layers.3.adapter_layer_ff.layernorm.weight', 'encoder.layers.3.adapter_layer_ff.linear_down.bias', 'encoder.layers.3.adapter_layer_ff.linear_down.weight', 'encoder.layers.3.adapter_layer_ff.linear_up.bias', 'encoder.layers.3.adapter_layer_ff.linear_up.weight', 'encoder.layers.4.adapter_layer_attn.layernorm.bias', 'encoder.layers.4.adapter_layer_attn.layernorm.weight', 'encoder.layers.4.adapter_layer_attn.linear_down.bias', 'encoder.layers.4.adapter_layer_attn.linear_down.weight', 'encoder.layers.4.adapter_layer_attn.linear_up.bias', 'encoder.layers.4.adapter_layer_attn.linear_up.weight', 'encoder.layers.4.adapter_layer_ff.layernorm.bias', 'encoder.layers.4.adapter_layer_ff.layernorm.weight', 'encoder.layers.4.adapter_layer_ff.linear_down.bias', 'encoder.layers.4.adapter_layer_ff.linear_down.weight', 'encoder.layers.4.adapter_layer_ff.linear_up.bias', 'encoder.layers.4.adapter_layer_ff.linear_up.weight', 'encoder.layers.5.adapter_layer_attn.layernorm.bias', 'encoder.layers.5.adapter_layer_attn.layernorm.weight', 'encoder.layers.5.adapter_layer_attn.linear_down.bias', 'encoder.layers.5.adapter_layer_attn.linear_down.weight', 'encoder.layers.5.adapter_layer_attn.linear_up.bias', 'encoder.layers.5.adapter_layer_attn.linear_up.weight', 'encoder.layers.5.adapter_layer_ff.layernorm.bias', 'encoder.layers.5.adapter_layer_ff.layernorm.weight', 'encoder.layers.5.adapter_layer_ff.linear_down.bias', 'encoder.layers.5.adapter_layer_ff.linear_down.weight', 'encoder.layers.5.adapter_layer_ff.linear_up.bias', 'encoder.layers.5.adapter_layer_ff.linear_up.weight', 'encoder.layers.6.adapter_layer_attn.layernorm.bias', 'encoder.layers.6.adapter_layer_attn.layernorm.weight', 'encoder.layers.6.adapter_layer_attn.linear_down.bias', 'encoder.layers.6.adapter_layer_attn.linear_down.weight', 'encoder.layers.6.adapter_layer_attn.linear_up.bias', 'encoder.layers.6.adapter_layer_attn.linear_up.weight', 'encoder.layers.6.adapter_layer_ff.layernorm.bias', 'encoder.layers.6.adapter_layer_ff.layernorm.weight', 'encoder.layers.6.adapter_layer_ff.linear_down.bias', 'encoder.layers.6.adapter_layer_ff.linear_down.weight', 'encoder.layers.6.adapter_layer_ff.linear_up.bias', 'encoder.layers.6.adapter_layer_ff.linear_up.weight', 'encoder.layers.7.adapter_layer_attn.layernorm.bias', 'encoder.layers.7.adapter_layer_attn.layernorm.weight', 'encoder.layers.7.adapter_layer_attn.linear_down.bias', 'encoder.layers.7.adapter_layer_attn.linear_down.weight', 'encoder.layers.7.adapter_layer_attn.linear_up.bias', 'encoder.layers.7.adapter_layer_attn.linear_up.weight', 'encoder.layers.7.adapter_layer_ff.layernorm.bias', 'encoder.layers.7.adapter_layer_ff.layernorm.weight', 'encoder.layers.7.adapter_layer_ff.linear_down.bias', 'encoder.layers.7.adapter_layer_ff.linear_down.weight', 'encoder.layers.7.adapter_layer_ff.linear_up.bias', 'encoder.layers.7.adapter_layer_ff.linear_up.weight', 'encoder.layers.8.adapter_layer_attn.layernorm.bias', 'encoder.layers.8.adapter_layer_attn.layernorm.weight', 'encoder.layers.8.adapter_layer_attn.linear_down.bias', 'encoder.layers.8.adapter_layer_attn.linear_down.weight', 'encoder.layers.8.adapter_layer_attn.linear_up.bias', 'encoder.layers.8.adapter_layer_attn.linear_up.weight', 'encoder.layers.8.adapter_layer_ff.layernorm.bias', 'encoder.layers.8.adapter_layer_ff.layernorm.weight', 'encoder.layers.8.adapter_layer_ff.linear_down.bias', 'encoder.layers.8.adapter_layer_ff.linear_down.weight', 'encoder.layers.8.adapter_layer_ff.linear_up.bias', 'encoder.layers.8.adapter_layer_ff.linear_up.weight', 'encoder.layers.9.adapter_layer_attn.layernorm.bias', 'encoder.layers.9.adapter_layer_attn.layernorm.weight', 'encoder.layers.9.adapter_layer_attn.linear_down.bias', 'encoder.layers.9.adapter_layer_attn.linear_down.weight', 'encoder.layers.9.adapter_layer_attn.linear_up.bias', 'encoder.layers.9.adapter_layer_attn.linear_up.weight', 'encoder.layers.9.adapter_layer_ff.layernorm.bias', 'encoder.layers.9.adapter_layer_ff.layernorm.weight', 'encoder.layers.9.adapter_layer_ff.linear_down.bias', 'encoder.layers.9.adapter_layer_ff.linear_down.weight', 'encoder.layers.9.adapter_layer_ff.linear_up.bias', 'encoder.layers.9.adapter_layer_ff.linear_up.weight', 'lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
2.6.0+cu124
2.6.0+cu124
frozen:  wavlm.masked_spec_embed
frozen:  wavlm.feature_extractor.conv_layers.0.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.0.layer_norm.weight
frozen:  wavlm.feature_extractor.conv_layers.0.layer_norm.bias
frozen:  wavlm.feature_extractor.conv_layers.1.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.2.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.3.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.4.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.5.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.6.conv.weight
frozen:  wavlm.feature_projection.layer_norm.weight
frozen:  wavlm.feature_projection.layer_norm.bias
frozen:  wavlm.feature_projection.projection.weight
frozen:  wavlm.feature_projection.projection.bias
frozen:  wavlm.encoder.pos_conv_embed.conv.bias
frozen:  wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original0
frozen:  wavlm.encoder.pos_conv_embed.conv.parametrizations.weight.original1
frozen:  wavlm.encoder.layer_norm.weight
frozen:  wavlm.encoder.layer_norm.bias
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.0.attention.k_proj.weight
frozen:  wavlm.encoder.layers.0.attention.k_proj.bias
frozen:  wavlm.encoder.layers.0.attention.v_proj.weight
frozen:  wavlm.encoder.layers.0.attention.v_proj.bias
frozen:  wavlm.encoder.layers.0.attention.q_proj.weight
frozen:  wavlm.encoder.layers.0.attention.q_proj.bias
frozen:  wavlm.encoder.layers.0.attention.out_proj.weight
frozen:  wavlm.encoder.layers.0.attention.out_proj.bias
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_linear.bias
frozen:  wavlm.encoder.layers.0.attention.rel_attn_embed.weight
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.0.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.0.layer_norm.weight
layer_norm:  wavlm.encoder.layers.0.layer_norm.bias
frozen:  wavlm.encoder.layers.0.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.0.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.0.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.0.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.0.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.0.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.0.final_layer_norm.bias
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.1.attention.k_proj.weight
frozen:  wavlm.encoder.layers.1.attention.k_proj.bias
frozen:  wavlm.encoder.layers.1.attention.v_proj.weight
frozen:  wavlm.encoder.layers.1.attention.v_proj.bias
frozen:  wavlm.encoder.layers.1.attention.q_proj.weight
frozen:  wavlm.encoder.layers.1.attention.q_proj.bias
frozen:  wavlm.encoder.layers.1.attention.out_proj.weight
frozen:  wavlm.encoder.layers.1.attention.out_proj.bias
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.1.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.1.layer_norm.weight
layer_norm:  wavlm.encoder.layers.1.layer_norm.bias
frozen:  wavlm.encoder.layers.1.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.1.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.1.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.1.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.1.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.1.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.1.final_layer_norm.bias
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.2.attention.k_proj.weight
frozen:  wavlm.encoder.layers.2.attention.k_proj.bias
frozen:  wavlm.encoder.layers.2.attention.v_proj.weight
frozen:  wavlm.encoder.layers.2.attention.v_proj.bias
frozen:  wavlm.encoder.layers.2.attention.q_proj.weight
frozen:  wavlm.encoder.layers.2.attention.q_proj.bias
frozen:  wavlm.encoder.layers.2.attention.out_proj.weight
frozen:  wavlm.encoder.layers.2.attention.out_proj.bias
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.2.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.2.layer_norm.weight
layer_norm:  wavlm.encoder.layers.2.layer_norm.bias
frozen:  wavlm.encoder.layers.2.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.2.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.2.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.2.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.2.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.2.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.2.final_layer_norm.bias
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.3.attention.k_proj.weight
frozen:  wavlm.encoder.layers.3.attention.k_proj.bias
frozen:  wavlm.encoder.layers.3.attention.v_proj.weight
frozen:  wavlm.encoder.layers.3.attention.v_proj.bias
frozen:  wavlm.encoder.layers.3.attention.q_proj.weight
frozen:  wavlm.encoder.layers.3.attention.q_proj.bias
frozen:  wavlm.encoder.layers.3.attention.out_proj.weight
frozen:  wavlm.encoder.layers.3.attention.out_proj.bias
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.3.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.3.layer_norm.weight
layer_norm:  wavlm.encoder.layers.3.layer_norm.bias
frozen:  wavlm.encoder.layers.3.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.3.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.3.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.3.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.3.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.3.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.3.final_layer_norm.bias
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.4.attention.k_proj.weight
frozen:  wavlm.encoder.layers.4.attention.k_proj.bias
frozen:  wavlm.encoder.layers.4.attention.v_proj.weight
frozen:  wavlm.encoder.layers.4.attention.v_proj.bias
frozen:  wavlm.encoder.layers.4.attention.q_proj.weight
frozen:  wavlm.encoder.layers.4.attention.q_proj.bias
frozen:  wavlm.encoder.layers.4.attention.out_proj.weight
frozen:  wavlm.encoder.layers.4.attention.out_proj.bias
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.4.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.4.layer_norm.weight
layer_norm:  wavlm.encoder.layers.4.layer_norm.bias
frozen:  wavlm.encoder.layers.4.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.4.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.4.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.4.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.4.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.4.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.4.final_layer_norm.bias
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.5.attention.k_proj.weight
frozen:  wavlm.encoder.layers.5.attention.k_proj.bias
frozen:  wavlm.encoder.layers.5.attention.v_proj.weight
frozen:  wavlm.encoder.layers.5.attention.v_proj.bias
frozen:  wavlm.encoder.layers.5.attention.q_proj.weight
frozen:  wavlm.encoder.layers.5.attention.q_proj.bias
frozen:  wavlm.encoder.layers.5.attention.out_proj.weight
frozen:  wavlm.encoder.layers.5.attention.out_proj.bias
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.5.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.5.layer_norm.weight
layer_norm:  wavlm.encoder.layers.5.layer_norm.bias
frozen:  wavlm.encoder.layers.5.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.5.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.5.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.5.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.5.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.5.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.5.final_layer_norm.bias
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.6.attention.k_proj.weight
frozen:  wavlm.encoder.layers.6.attention.k_proj.bias
frozen:  wavlm.encoder.layers.6.attention.v_proj.weight
frozen:  wavlm.encoder.layers.6.attention.v_proj.bias
frozen:  wavlm.encoder.layers.6.attention.q_proj.weight
frozen:  wavlm.encoder.layers.6.attention.q_proj.bias
frozen:  wavlm.encoder.layers.6.attention.out_proj.weight
frozen:  wavlm.encoder.layers.6.attention.out_proj.bias
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.6.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.6.layer_norm.weight
layer_norm:  wavlm.encoder.layers.6.layer_norm.bias
frozen:  wavlm.encoder.layers.6.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.6.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.6.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.6.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.6.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.6.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.6.final_layer_norm.bias
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.7.attention.k_proj.weight
frozen:  wavlm.encoder.layers.7.attention.k_proj.bias
frozen:  wavlm.encoder.layers.7.attention.v_proj.weight
frozen:  wavlm.encoder.layers.7.attention.v_proj.bias
frozen:  wavlm.encoder.layers.7.attention.q_proj.weight
frozen:  wavlm.encoder.layers.7.attention.q_proj.bias
frozen:  wavlm.encoder.layers.7.attention.out_proj.weight
frozen:  wavlm.encoder.layers.7.attention.out_proj.bias
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.7.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.7.layer_norm.weight
layer_norm:  wavlm.encoder.layers.7.layer_norm.bias
frozen:  wavlm.encoder.layers.7.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.7.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.7.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.7.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.7.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.7.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.7.final_layer_norm.bias
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.8.attention.k_proj.weight
frozen:  wavlm.encoder.layers.8.attention.k_proj.bias
frozen:  wavlm.encoder.layers.8.attention.v_proj.weight
frozen:  wavlm.encoder.layers.8.attention.v_proj.bias
frozen:  wavlm.encoder.layers.8.attention.q_proj.weight
frozen:  wavlm.encoder.layers.8.attention.q_proj.bias
frozen:  wavlm.encoder.layers.8.attention.out_proj.weight
frozen:  wavlm.encoder.layers.8.attention.out_proj.bias
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.8.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.8.layer_norm.weight
layer_norm:  wavlm.encoder.layers.8.layer_norm.bias
frozen:  wavlm.encoder.layers.8.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.8.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.8.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.8.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.8.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.8.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.8.final_layer_norm.bias
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.9.attention.k_proj.weight
frozen:  wavlm.encoder.layers.9.attention.k_proj.bias
frozen:  wavlm.encoder.layers.9.attention.v_proj.weight
frozen:  wavlm.encoder.layers.9.attention.v_proj.bias
frozen:  wavlm.encoder.layers.9.attention.q_proj.weight
frozen:  wavlm.encoder.layers.9.attention.q_proj.bias
frozen:  wavlm.encoder.layers.9.attention.out_proj.weight
frozen:  wavlm.encoder.layers.9.attention.out_proj.bias
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.9.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.9.layer_norm.weight
layer_norm:  wavlm.encoder.layers.9.layer_norm.bias
frozen:  wavlm.encoder.layers.9.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.9.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.9.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.9.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.9.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.9.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.9.final_layer_norm.bias
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.10.attention.k_proj.weight
frozen:  wavlm.encoder.layers.10.attention.k_proj.bias
frozen:  wavlm.encoder.layers.10.attention.v_proj.weight
frozen:  wavlm.encoder.layers.10.attention.v_proj.bias
frozen:  wavlm.encoder.layers.10.attention.q_proj.weight
frozen:  wavlm.encoder.layers.10.attention.q_proj.bias
frozen:  wavlm.encoder.layers.10.attention.out_proj.weight
frozen:  wavlm.encoder.layers.10.attention.out_proj.bias
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.10.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.10.layer_norm.weight
layer_norm:  wavlm.encoder.layers.10.layer_norm.bias
frozen:  wavlm.encoder.layers.10.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.10.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.10.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.10.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.10.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.10.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.10.final_layer_norm.bias
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.11.attention.k_proj.weight
frozen:  wavlm.encoder.layers.11.attention.k_proj.bias
frozen:  wavlm.encoder.layers.11.attention.v_proj.weight
frozen:  wavlm.encoder.layers.11.attention.v_proj.bias
frozen:  wavlm.encoder.layers.11.attention.q_proj.weight
frozen:  wavlm.encoder.layers.11.attention.q_proj.bias
frozen:  wavlm.encoder.layers.11.attention.out_proj.weight
frozen:  wavlm.encoder.layers.11.attention.out_proj.bias
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_linear.bias
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.linear_down.weight
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.linear_down.bias
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.linear_up.weight
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.linear_up.bias
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.layernorm.weight
enc_adapter_attn:  wavlm.encoder.layers.11.adapter_layer_attn.layernorm.bias
layer_norm:  wavlm.encoder.layers.11.layer_norm.weight
layer_norm:  wavlm.encoder.layers.11.layer_norm.bias
frozen:  wavlm.encoder.layers.11.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.11.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.11.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.11.feed_forward.output_dense.bias
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.linear_down.weight
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.linear_down.bias
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.linear_up.weight
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.linear_up.bias
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.layernorm.weight
enc_adapter_ff:  wavlm.encoder.layers.11.adapter_layer_ff.layernorm.bias
layer_norm:  wavlm.encoder.layers.11.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.11.final_layer_norm.bias
down_param:  lm_head.weight
down_param:  lm_head.bias

count of parameters:  9560096 


count of adapter_parameters:  9498624 

  0%|          | 0/100 [00:00<?, ?it/s]
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
Traceback (most recent call last):
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/train.py", line 318, in <module>
    main()
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/train.py", line 307, in main
    model = train_model(model, processor, dataloaders_dict, optimizer, scheduler, metric, num_epochs, report_wandb=False, val_interval=100)
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/utils.py", line 157, in train_model
    for step, inputs in enumerate(dataloaders_dict[phase]):
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1480, in _next_data
    return self._process_data(data)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1505, in _process_data
    data.reraise()
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/_utils.py", line 733, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/utils.py", line 44, in __getitem__
    labels = self.processor(text).input_ids
  File "/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 104, in __call__
    return self.current_processor(
TypeError: Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<pad>", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),
	1: AddedToken("<s>", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),
	2: AddedToken("</s>", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),
	3: AddedToken("<unk>", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),
}
) got multiple values for keyword argument 'return_attention_mask'

/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:174: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
 
---------- Step 1: Processing complete  ----------------------
