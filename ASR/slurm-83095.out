 
---------- Step 0: Installing libraries  --------------
 
Requirement already satisfied: datasets in /scratch/skscla001/.local/lib/python3.9/site-packages (3.3.2)
Requirement already satisfied: filelock in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (3.17.0)
Requirement already satisfied: numpy>=1.17 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from datasets) (1.26.4)
Requirement already satisfied: pyarrow>=15.0.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (19.0.1)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (1.4.3)
Requirement already satisfied: requests>=2.32.2 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from datasets) (2.32.3)
Requirement already satisfied: tqdm>=4.66.3 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from datasets) (4.66.4)
Requirement already satisfied: xxhash in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (0.70.16)
Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)
Requirement already satisfied: aiohttp in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (3.11.13)
Requirement already satisfied: huggingface-hub>=0.24.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (0.29.1)
Requirement already satisfied: packaging in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from datasets) (24.1)
Requirement already satisfied: pyyaml>=5.1 in /scratch/skscla001/.local/lib/python3.9/site-packages (from datasets) (6.0.2)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (2.4.6)
Requirement already satisfied: aiosignal>=1.1.2 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.2)
Requirement already satisfied: async-timeout<6.0,>=4.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (5.0.1)
Requirement already satisfied: attrs>=17.3.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (25.1.0)
Requirement already satisfied: frozenlist>=1.1.1 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.5.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.1.0)
Requirement already satisfied: propcache>=0.2.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (0.3.0)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /scratch/skscla001/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.18.3)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /scratch/skscla001/.local/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2024.8.30)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /scratch/skscla001/.local/lib/python3.9/site-packages (from pandas->datasets) (2025.1)
Requirement already satisfied: six>=1.5 in /opt/exp_soft/miniconda3-py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)
Collecting evaluate
  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)
Collecting datasets>=2.0.0 (from evaluate)
  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)
Collecting numpy>=1.17 (from evaluate)
  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
Collecting dill (from evaluate)
  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)
Collecting pandas (from evaluate)
  Using cached pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
Collecting requests>=2.19.0 (from evaluate)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting tqdm>=4.62.1 (from evaluate)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting xxhash (from evaluate)
  Using cached xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess (from evaluate)
  Using cached multiprocess-0.70.17-py39-none-any.whl.metadata (7.2 kB)
Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)
  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)
Collecting huggingface-hub>=0.7.0 (from evaluate)
  Using cached huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)
Collecting packaging (from evaluate)
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting filelock (from datasets>=2.0.0->evaluate)
  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)
Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)
  Using cached pyarrow-19.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill (from evaluate)
  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Collecting multiprocess (from evaluate)
  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)
Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)
  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting aiohttp (from datasets>=2.0.0->evaluate)
  Using cached aiohttp-3.11.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting pyyaml>=5.1 (from datasets>=2.0.0->evaluate)
  Using cached PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.7.0->evaluate)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->evaluate)
  Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
Collecting idna<4,>=2.5 (from requests>=2.19.0->evaluate)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->evaluate)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests>=2.19.0->evaluate)
  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
Collecting python-dateutil>=2.8.2 (from pandas->evaluate)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas->evaluate)
  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas->evaluate)
  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)
Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)
Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached propcache-0.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate)
  Using cached yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->evaluate)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)
Using cached datasets-3.3.2-py3-none-any.whl (485 kB)
Using cached dill-0.3.8-py3-none-any.whl (116 kB)
Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)
Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)
Using cached multiprocess-0.70.16-py39-none-any.whl (133 kB)
Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Using cached xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)
Using cached aiohttp-3.11.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached pyarrow-19.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (42.1 MB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)
Using cached PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Using cached filelock-3.17.0-py3-none-any.whl (16 kB)
Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)
Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)
Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
Using cached attrs-25.1.0-py3-none-any.whl (63 kB)
Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)
Using cached multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)
Using cached propcache-0.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)
Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, pyyaml, pyarrow, propcache, packaging, numpy, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, requests, python-dateutil, multiprocess, multidict, aiosignal, yarl, pandas, huggingface-hub, aiohttp, datasets, evaluate
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.2 which is incompatible.
hyperpyyaml 1.2.2 requires ruamel.yaml>=0.17.28, but you have ruamel-yaml 0.17.21 which is incompatible.
Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.1 idna-3.10 multidict-6.1.0 multiprocess-0.70.16 numpy-1.23.1 packaging-24.2 pandas-1.4.3 propcache-0.3.0 pyarrow-19.0.1 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 requests-2.32.3 six-1.17.0 tqdm-4.64.0 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0 xxhash-3.5.0 yarl-1.18.3
Collecting jiwer
  Using cached jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Collecting click>=8.1.8 (from jiwer)
  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)
Collecting rapidfuzz>=3.9.7 (from jiwer)
  Using cached rapidfuzz-3.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Using cached jiwer-3.1.0-py3-none-any.whl (22 kB)
Using cached click-8.1.8-py3-none-any.whl (98 kB)
Using cached rapidfuzz-3.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
Installing collected packages: rapidfuzz, click, jiwer
Successfully installed click-8.1.8 jiwer-3.1.0 rapidfuzz-3.12.1
---------- Step 1: Running model ----------------------
Some weights of AdaWavLMForCTC were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.adapter_to_output.5.linear_down.bias', 'encoder.adapter_to_output.2.linear_down.bias', 'encoder.adapter_to_output.0.linear_down.weight', 'encoder.adapter_to_output.4.linear_down.weight', 'encoder.adapter_to_output.9.linear_down.bias', 'encoder.adapter_to_output.6.layernorm.bias', 'encoder.adapter_to_output.8.layernorm.bias', 'encoder.adapter_to_output.3.layernorm.bias', 'lm_head.weight', 'encoder.adapter_to_output.1.layernorm.weight', 'encoder.adapter_to_output.7.linear_down.bias', 'encoder.adapter_to_output.11.linear_down.bias', 'encoder.adapter_to_output.10.layernorm.weight', 'encoder.adapter_to_output.9.linear_down.weight', 'encoder.adapter_to_output.1.linear_down.bias', 'encoder.adapter_to_output.4.linear_down.bias', 'encoder.adapter_to_output.5.layernorm.weight', 'encoder.adapter_to_output.3.linear_down.bias', 'encoder.adapter_to_output.11.linear_down.weight', 'encoder.adapter_to_output.8.linear_down.weight', 'encoder.adapter_to_output.10.linear_down.weight', 'encoder.adapter_to_output.2.layernorm.bias', 'encoder.adapter_to_output.6.linear_down.bias', 'encoder.adapter_to_output.3.linear_down.weight', 'encoder.adapter_to_output.1.layernorm.bias', 'encoder.adapter_to_output.7.layernorm.bias', 'encoder.adapter_to_output_layer_weights', 'lm_head.bias', 'encoder.adapter_to_output.0.layernorm.weight', 'encoder.adapter_to_output.4.layernorm.weight', 'encoder.adapter_to_output.5.linear_down.weight', 'encoder.adapter_to_output.10.layernorm.bias', 'encoder.adapter_to_output.0.layernorm.bias', 'encoder.adapter_to_output.2.linear_down.weight', 'encoder.adapter_to_output.6.linear_down.weight', 'encoder.adapter_to_output.8.layernorm.weight', 'encoder.adapter_to_output.6.layernorm.weight', 'encoder.adapter_to_output.7.linear_down.weight', 'encoder.adapter_to_output.11.layernorm.bias', 'encoder.adapter_to_output.9.layernorm.weight', 'encoder.adapter_to_output.1.linear_down.weight', 'encoder.adapter_to_output.10.linear_down.bias', 'encoder.adapter_to_output.4.layernorm.bias', 'encoder.adapter_to_output.0.linear_down.bias', 'encoder.adapter_to_output.2.layernorm.weight', 'encoder.adapter_to_output.11.layernorm.weight', 'encoder.adapter_to_output.8.linear_down.bias', 'encoder.adapter_to_output.3.layernorm.weight', 'encoder.adapter_to_output.5.layernorm.bias', 'encoder.adapter_to_output.9.layernorm.bias', 'encoder.adapter_to_output.7.layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/skscla001/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/skscla001/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:145: UserWarning: 
NVIDIA A100 80GB PCIe with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the NVIDIA A100 80GB PCIe GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
frozen:  wavlm.masked_spec_embed
frozen:  wavlm.feature_extractor.conv_layers.0.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.0.layer_norm.weight
frozen:  wavlm.feature_extractor.conv_layers.0.layer_norm.bias
frozen:  wavlm.feature_extractor.conv_layers.1.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.2.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.3.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.4.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.5.conv.weight
frozen:  wavlm.feature_extractor.conv_layers.6.conv.weight
frozen:  wavlm.feature_projection.layer_norm.weight
frozen:  wavlm.feature_projection.layer_norm.bias
frozen:  wavlm.feature_projection.projection.weight
frozen:  wavlm.feature_projection.projection.bias
adapter_to_output_layer_weights:  wavlm.encoder.adapter_to_output_layer_weights
frozen:  wavlm.encoder.pos_conv_embed.conv.bias
frozen:  wavlm.encoder.pos_conv_embed.conv.weight_g
frozen:  wavlm.encoder.pos_conv_embed.conv.weight_v
frozen:  wavlm.encoder.layer_norm.weight
frozen:  wavlm.encoder.layer_norm.bias
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.0.attention.k_proj.weight
frozen:  wavlm.encoder.layers.0.attention.k_proj.bias
frozen:  wavlm.encoder.layers.0.attention.v_proj.weight
frozen:  wavlm.encoder.layers.0.attention.v_proj.bias
frozen:  wavlm.encoder.layers.0.attention.q_proj.weight
frozen:  wavlm.encoder.layers.0.attention.q_proj.bias
frozen:  wavlm.encoder.layers.0.attention.out_proj.weight
frozen:  wavlm.encoder.layers.0.attention.out_proj.bias
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.0.attention.gru_rel_pos_linear.bias
frozen:  wavlm.encoder.layers.0.attention.rel_attn_embed.weight
layer_norm:  wavlm.encoder.layers.0.layer_norm.weight
layer_norm:  wavlm.encoder.layers.0.layer_norm.bias
frozen:  wavlm.encoder.layers.0.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.0.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.0.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.0.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.0.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.0.final_layer_norm.bias
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.1.attention.k_proj.weight
frozen:  wavlm.encoder.layers.1.attention.k_proj.bias
frozen:  wavlm.encoder.layers.1.attention.v_proj.weight
frozen:  wavlm.encoder.layers.1.attention.v_proj.bias
frozen:  wavlm.encoder.layers.1.attention.q_proj.weight
frozen:  wavlm.encoder.layers.1.attention.q_proj.bias
frozen:  wavlm.encoder.layers.1.attention.out_proj.weight
frozen:  wavlm.encoder.layers.1.attention.out_proj.bias
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.1.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.1.layer_norm.weight
layer_norm:  wavlm.encoder.layers.1.layer_norm.bias
frozen:  wavlm.encoder.layers.1.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.1.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.1.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.1.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.1.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.1.final_layer_norm.bias
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.2.attention.k_proj.weight
frozen:  wavlm.encoder.layers.2.attention.k_proj.bias
frozen:  wavlm.encoder.layers.2.attention.v_proj.weight
frozen:  wavlm.encoder.layers.2.attention.v_proj.bias
frozen:  wavlm.encoder.layers.2.attention.q_proj.weight
frozen:  wavlm.encoder.layers.2.attention.q_proj.bias
frozen:  wavlm.encoder.layers.2.attention.out_proj.weight
frozen:  wavlm.encoder.layers.2.attention.out_proj.bias
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.2.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.2.layer_norm.weight
layer_norm:  wavlm.encoder.layers.2.layer_norm.bias
frozen:  wavlm.encoder.layers.2.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.2.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.2.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.2.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.2.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.2.final_layer_norm.bias
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.3.attention.k_proj.weight
frozen:  wavlm.encoder.layers.3.attention.k_proj.bias
frozen:  wavlm.encoder.layers.3.attention.v_proj.weight
frozen:  wavlm.encoder.layers.3.attention.v_proj.bias
frozen:  wavlm.encoder.layers.3.attention.q_proj.weight
frozen:  wavlm.encoder.layers.3.attention.q_proj.bias
frozen:  wavlm.encoder.layers.3.attention.out_proj.weight
frozen:  wavlm.encoder.layers.3.attention.out_proj.bias
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.3.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.3.layer_norm.weight
layer_norm:  wavlm.encoder.layers.3.layer_norm.bias
frozen:  wavlm.encoder.layers.3.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.3.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.3.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.3.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.3.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.3.final_layer_norm.bias
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.4.attention.k_proj.weight
frozen:  wavlm.encoder.layers.4.attention.k_proj.bias
frozen:  wavlm.encoder.layers.4.attention.v_proj.weight
frozen:  wavlm.encoder.layers.4.attention.v_proj.bias
frozen:  wavlm.encoder.layers.4.attention.q_proj.weight
frozen:  wavlm.encoder.layers.4.attention.q_proj.bias
frozen:  wavlm.encoder.layers.4.attention.out_proj.weight
frozen:  wavlm.encoder.layers.4.attention.out_proj.bias
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.4.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.4.layer_norm.weight
layer_norm:  wavlm.encoder.layers.4.layer_norm.bias
frozen:  wavlm.encoder.layers.4.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.4.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.4.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.4.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.4.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.4.final_layer_norm.bias
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.5.attention.k_proj.weight
frozen:  wavlm.encoder.layers.5.attention.k_proj.bias
frozen:  wavlm.encoder.layers.5.attention.v_proj.weight
frozen:  wavlm.encoder.layers.5.attention.v_proj.bias
frozen:  wavlm.encoder.layers.5.attention.q_proj.weight
frozen:  wavlm.encoder.layers.5.attention.q_proj.bias
frozen:  wavlm.encoder.layers.5.attention.out_proj.weight
frozen:  wavlm.encoder.layers.5.attention.out_proj.bias
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.5.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.5.layer_norm.weight
layer_norm:  wavlm.encoder.layers.5.layer_norm.bias
frozen:  wavlm.encoder.layers.5.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.5.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.5.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.5.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.5.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.5.final_layer_norm.bias
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.6.attention.k_proj.weight
frozen:  wavlm.encoder.layers.6.attention.k_proj.bias
frozen:  wavlm.encoder.layers.6.attention.v_proj.weight
frozen:  wavlm.encoder.layers.6.attention.v_proj.bias
frozen:  wavlm.encoder.layers.6.attention.q_proj.weight
frozen:  wavlm.encoder.layers.6.attention.q_proj.bias
frozen:  wavlm.encoder.layers.6.attention.out_proj.weight
frozen:  wavlm.encoder.layers.6.attention.out_proj.bias
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.6.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.6.layer_norm.weight
layer_norm:  wavlm.encoder.layers.6.layer_norm.bias
frozen:  wavlm.encoder.layers.6.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.6.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.6.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.6.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.6.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.6.final_layer_norm.bias
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.7.attention.k_proj.weight
frozen:  wavlm.encoder.layers.7.attention.k_proj.bias
frozen:  wavlm.encoder.layers.7.attention.v_proj.weight
frozen:  wavlm.encoder.layers.7.attention.v_proj.bias
frozen:  wavlm.encoder.layers.7.attention.q_proj.weight
frozen:  wavlm.encoder.layers.7.attention.q_proj.bias
frozen:  wavlm.encoder.layers.7.attention.out_proj.weight
frozen:  wavlm.encoder.layers.7.attention.out_proj.bias
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.7.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.7.layer_norm.weight
layer_norm:  wavlm.encoder.layers.7.layer_norm.bias
frozen:  wavlm.encoder.layers.7.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.7.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.7.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.7.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.7.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.7.final_layer_norm.bias
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.8.attention.k_proj.weight
frozen:  wavlm.encoder.layers.8.attention.k_proj.bias
frozen:  wavlm.encoder.layers.8.attention.v_proj.weight
frozen:  wavlm.encoder.layers.8.attention.v_proj.bias
frozen:  wavlm.encoder.layers.8.attention.q_proj.weight
frozen:  wavlm.encoder.layers.8.attention.q_proj.bias
frozen:  wavlm.encoder.layers.8.attention.out_proj.weight
frozen:  wavlm.encoder.layers.8.attention.out_proj.bias
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.8.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.8.layer_norm.weight
layer_norm:  wavlm.encoder.layers.8.layer_norm.bias
frozen:  wavlm.encoder.layers.8.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.8.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.8.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.8.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.8.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.8.final_layer_norm.bias
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.9.attention.k_proj.weight
frozen:  wavlm.encoder.layers.9.attention.k_proj.bias
frozen:  wavlm.encoder.layers.9.attention.v_proj.weight
frozen:  wavlm.encoder.layers.9.attention.v_proj.bias
frozen:  wavlm.encoder.layers.9.attention.q_proj.weight
frozen:  wavlm.encoder.layers.9.attention.q_proj.bias
frozen:  wavlm.encoder.layers.9.attention.out_proj.weight
frozen:  wavlm.encoder.layers.9.attention.out_proj.bias
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.9.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.9.layer_norm.weight
layer_norm:  wavlm.encoder.layers.9.layer_norm.bias
frozen:  wavlm.encoder.layers.9.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.9.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.9.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.9.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.9.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.9.final_layer_norm.bias
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.10.attention.k_proj.weight
frozen:  wavlm.encoder.layers.10.attention.k_proj.bias
frozen:  wavlm.encoder.layers.10.attention.v_proj.weight
frozen:  wavlm.encoder.layers.10.attention.v_proj.bias
frozen:  wavlm.encoder.layers.10.attention.q_proj.weight
frozen:  wavlm.encoder.layers.10.attention.q_proj.bias
frozen:  wavlm.encoder.layers.10.attention.out_proj.weight
frozen:  wavlm.encoder.layers.10.attention.out_proj.bias
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.10.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.10.layer_norm.weight
layer_norm:  wavlm.encoder.layers.10.layer_norm.bias
frozen:  wavlm.encoder.layers.10.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.10.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.10.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.10.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.10.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.10.final_layer_norm.bias
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_const
frozen:  wavlm.encoder.layers.11.attention.k_proj.weight
frozen:  wavlm.encoder.layers.11.attention.k_proj.bias
frozen:  wavlm.encoder.layers.11.attention.v_proj.weight
frozen:  wavlm.encoder.layers.11.attention.v_proj.bias
frozen:  wavlm.encoder.layers.11.attention.q_proj.weight
frozen:  wavlm.encoder.layers.11.attention.q_proj.bias
frozen:  wavlm.encoder.layers.11.attention.out_proj.weight
frozen:  wavlm.encoder.layers.11.attention.out_proj.bias
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_linear.weight
frozen:  wavlm.encoder.layers.11.attention.gru_rel_pos_linear.bias
layer_norm:  wavlm.encoder.layers.11.layer_norm.weight
layer_norm:  wavlm.encoder.layers.11.layer_norm.bias
frozen:  wavlm.encoder.layers.11.feed_forward.intermediate_dense.weight
frozen:  wavlm.encoder.layers.11.feed_forward.intermediate_dense.bias
frozen:  wavlm.encoder.layers.11.feed_forward.output_dense.weight
frozen:  wavlm.encoder.layers.11.feed_forward.output_dense.bias
layer_norm:  wavlm.encoder.layers.11.final_layer_norm.weight
layer_norm:  wavlm.encoder.layers.11.final_layer_norm.bias
adapter_output:  wavlm.encoder.adapter_to_output.0.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.0.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.0.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.0.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.1.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.1.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.1.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.1.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.2.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.2.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.2.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.2.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.3.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.3.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.3.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.3.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.4.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.4.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.4.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.4.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.5.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.5.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.5.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.5.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.6.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.6.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.6.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.6.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.7.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.7.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.7.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.7.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.8.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.8.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.8.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.8.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.9.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.9.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.9.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.9.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.10.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.10.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.10.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.10.layernorm.bias
adapter_output:  wavlm.encoder.adapter_to_output.11.linear_down.weight
adapter_output:  wavlm.encoder.adapter_to_output.11.linear_down.bias
adapter_output:  wavlm.encoder.adapter_to_output.11.layernorm.weight
adapter_output:  wavlm.encoder.adapter_to_output.11.layernorm.bias
down_param:  lm_head.weight
down_param:  lm_head.bias

count of parameters:  4790316 


count of adapter_parameters:  4737036 

  0%|          | 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/train.py", line 314, in <module>
    main()
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/train.py", line 303, in main
    model = train_model(model, processor, dataloaders_dict, optimizer, scheduler, metric, num_epochs, report_wandb=False, val_interval=100)
  File "/scratch/skscla001/speech/adapter-wavlm/ASR/utils.py", line 166, in train_model
    outputs = model(**inputs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wavlm/modeling_wavlm.py", line 1349, in forward
    outputs = self.wavlm(
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wavlm/modeling_wavlm.py", line 1237, in forward
    extract_features = self.feature_extractor(input_values)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wavlm/modeling_wavlm.py", line 373, in forward
    hidden_states = conv_layer(hidden_states)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/transformers/models/wavlm/modeling_wavlm.py", line 273, in forward
    hidden_states = self.layer_norm(hidden_states)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 268, in forward
    return F.group_norm(
  File "/home/skscla001/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2499, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
